#!/usr/bin/env python3
"""
å¤´éƒ¨åŒºåŸŸé”åº¦æµ‹è¯•è„šæœ¬
ä½¿ç”¨çœ¼ç›ä¸ºåœ†å¿ƒï¼Œçœ¼å–™è·ç¦»Ã—1.2ä¸ºåŠå¾„ï¼Œä¸segæ©ç å–äº¤é›†
"""

import os
import sys
import torch
import torch.nn as nn
import torchvision.models as models
from torchvision import transforms
from PIL import Image
import numpy as np
import cv2
import math

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from ultralytics import YOLO
from find_bird_util import raw_to_jpeg

# é…ç½®
MODEL_PATH = "models/cub200_keypoint_resnet50.pth"
YOLO_MODEL_PATH = "models/yolo11m-seg.pt"
IMG_SIZE = 416
OUTPUT_DIR = "/Users/jameszhenyu/Desktop/head_region_test"
RADIUS_MULTIPLIER = 1.2
NO_BEAK_RADIUS_RATIO = 0.15  # æ— å–™æ—¶ç”¨æ£€æµ‹æ¡†çš„15%


class PartLocalizer(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = models.resnet50(weights=None)
        in_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()
        self.head = nn.Sequential(
            nn.Linear(in_features, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(0.2),
            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.2),
        )
        self.coord_head = nn.Linear(256, 6)
        self.vis_head = nn.Linear(256, 3)

    def forward(self, x):
        features = self.head(self.backbone(x))
        coords = torch.sigmoid(self.coord_head(features)).view(-1, 3, 2)
        vis = torch.sigmoid(self.vis_head(features))
        return coords, vis


def calculate_distance(p1, p2):
    """è®¡ç®—ä¸¤ç‚¹è·ç¦»"""
    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)


def select_eye_for_center(left_eye, right_eye, beak, left_vis, right_vis):
    """
    é€‰æ‹©ç”¨å“ªåªçœ¼ç›ä½œä¸ºåœ†å¿ƒ
    è§„åˆ™ï¼šç”¨æ›´è¿œç¦»é¸Ÿå–™çš„é‚£åªçœ¼ç›
    """
    if left_vis >= 0.5 and right_vis >= 0.5:
        # ä¸¤çœ¼éƒ½å¯è§ï¼Œé€‰æ›´è¿œç¦»å–™çš„
        left_dist = calculate_distance(left_eye, beak)
        right_dist = calculate_distance(right_eye, beak)
        if left_dist >= right_dist:
            return left_eye, 'left'
        else:
            return right_eye, 'right'
    elif left_vis >= 0.5:
        return left_eye, 'left'
    elif right_vis >= 0.5:
        return right_eye, 'right'
    else:
        return None, None


def create_head_mask(image_shape, eye_center, radius, seg_mask):
    """
    åˆ›å»ºå¤´éƒ¨åŒºåŸŸæ©ç 
    = ä»¥çœ¼ç›ä¸ºåœ†å¿ƒçš„åœ† âˆ© é¸Ÿä½“segæ©ç 
    """
    h, w = image_shape[:2]
    
    # åˆ›å»ºåœ†å½¢æ©ç 
    circle_mask = np.zeros((h, w), dtype=np.uint8)
    cv2.circle(circle_mask, (int(eye_center[0]), int(eye_center[1])), int(radius), 255, -1)
    
    # ä¸segæ©ç å–äº¤é›†
    head_mask = cv2.bitwise_and(circle_mask, seg_mask)
    
    return head_mask, circle_mask


def calculate_sharpness(image, mask):
    """è®¡ç®—æ©ç åŒºåŸŸçš„é”åº¦"""
    if mask.sum() == 0:
        return 0.0
    
    # è½¬ç°åº¦
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image
    
    # åªåœ¨æ©ç åŒºåŸŸè®¡ç®—
    masked_gray = cv2.bitwise_and(gray, gray, mask=mask)
    
    # è®¡ç®—Laplacian
    laplacian = cv2.Laplacian(masked_gray, cv2.CV_64F)
    
    # åªå–æ©ç å†…çš„æ–¹å·®
    mask_pixels = mask > 0
    if mask_pixels.sum() == 0:
        return 0.0
    
    sharpness = laplacian[mask_pixels].var()
    return sharpness


def visualize_result(image, seg_mask, head_mask, circle_mask, eye_center, beak, radius, sharpness, filename, beak_visible=True):
    """å¯è§†åŒ–ç»“æœ"""
    vis_img = image.copy()
    h, w = image.shape[:2]
    
    # 1. ç»˜åˆ¶segæ©ç è½®å»“ï¼ˆç»¿è‰²ï¼‰
    contours, _ = cv2.findContours(seg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cv2.drawContours(vis_img, contours, -1, (0, 255, 0), 2)
    
    # 2. ç»˜åˆ¶å¤´éƒ¨åœ†ï¼ˆé»„è‰²è™šçº¿ï¼‰
    cv2.circle(vis_img, (int(eye_center[0]), int(eye_center[1])), int(radius), (255, 255, 0), 2)
    
    # 3. å¤´éƒ¨åŒºåŸŸå¡«å……è“è‰²åŠé€æ˜
    overlay = vis_img.copy()
    overlay[head_mask > 0] = [100, 150, 255]  # è“è‰²
    vis_img = cv2.addWeighted(overlay, 0.5, vis_img, 0.5, 0)
    
    # 4. æ ‡è®°çœ¼ç›ï¼ˆçº¢è‰²åœ†ç‚¹ï¼‰
    cv2.circle(vis_img, (int(eye_center[0]), int(eye_center[1])), 5, (255, 0, 0), -1)
    
    # 5. æ ‡è®°å–™ï¼ˆç»¿è‰²åœ†ç‚¹ï¼Œå¦‚æœå¯è§ï¼‰
    if beak_visible:
        cv2.circle(vis_img, (int(beak[0]), int(beak[1])), 5, (0, 255, 0), -1)
    
    # 6. æ·»åŠ æ–‡å­—
    cv2.putText(vis_img, f"Sharpness: {sharpness:.0f}", (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
    cv2.putText(vis_img, f"Radius: {radius:.0f}px", (10, 60),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
    
    # 7. å–™å¯è§æ€§æç¤º
    if not beak_visible:
        cv2.putText(vis_img, "NO BEAK (15% fallback)", (10, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 165, 255), 2)  # æ©™è‰²
    
    # ä¿å­˜
    output_path = os.path.join(OUTPUT_DIR, f"head_{filename}")
    cv2.imwrite(output_path, cv2.cvtColor(vis_img, cv2.COLOR_RGB2BGR))
    
    return output_path


def process_image(jpg_path, yolo_model, keypoint_model, device, transform):
    """å¤„ç†å•å¼ å›¾ç‰‡"""
    filename = os.path.basename(jpg_path)
    
    # YOLO æ£€æµ‹
    yolo_results = yolo_model(jpg_path, verbose=False)
    
    bird_crop = None
    seg_mask = None
    box = None
    
    for r in yolo_results:
        if r.boxes is not None and len(r.boxes) > 0:
            for i, cls in enumerate(r.boxes.cls):
                if int(cls) == 14:  # bird
                    box = r.boxes.xyxy[i].cpu().numpy().astype(int)
                    
                    # è·å–segæ©ç 
                    if r.masks is not None and i < len(r.masks):
                        mask = r.masks[i].data.cpu().numpy()[0]
                        seg_mask = (mask * 255).astype(np.uint8)
                        # resizeåˆ°åŸå›¾å¤§å°
                        img = cv2.imread(jpg_path)
                        seg_mask = cv2.resize(seg_mask, (img.shape[1], img.shape[0]))
                    
                    img = cv2.imread(jpg_path)
                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    bird_crop = img[box[1]:box[3], box[0]:box[2]]
                    break
        if bird_crop is not None:
            break
    
    if bird_crop is None or seg_mask is None:
        return None
    
    # å…³é”®ç‚¹æ£€æµ‹ï¼ˆåœ¨è£å‰ªåŒºåŸŸä¸Šï¼‰
    pil_crop = Image.fromarray(bird_crop)
    tensor = transform(pil_crop).unsqueeze(0).to(device)
    
    with torch.no_grad():
        coords, vis = keypoint_model(tensor)
    
    coords = coords[0].cpu().numpy()
    vis = vis[0].cpu().numpy()
    
    # åæ ‡è½¬æ¢åˆ°åŸå›¾
    crop_h, crop_w = bird_crop.shape[:2]
    left_eye = (coords[0, 0] * crop_w + box[0], coords[0, 1] * crop_h + box[1])
    right_eye = (coords[1, 0] * crop_w + box[0], coords[1, 1] * crop_h + box[1])
    beak = (coords[2, 0] * crop_w + box[0], coords[2, 1] * crop_h + box[1])
    
    # é€‰æ‹©çœ¼ç›
    eye_center, eye_name = select_eye_for_center(left_eye, right_eye, beak, vis[0], vis[1])
    
    if eye_center is None:
        return {'filename': filename, 'status': 'no_visible_eye'}
    
    # è®¡ç®—åŠå¾„
    beak_visible = vis[2] >= 0.5
    if beak_visible:  # å–™å¯è§
        radius = calculate_distance(eye_center, beak) * RADIUS_MULTIPLIER
    else:
        # å–™ä¸å¯è§ï¼Œç”¨æ£€æµ‹æ¡†çš„15%
        radius = max(box[2] - box[0], box[3] - box[1]) * NO_BEAK_RADIUS_RATIO
    
    # åˆ›å»ºå¤´éƒ¨æ©ç 
    img = cv2.imread(jpg_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    head_mask, circle_mask = create_head_mask(img.shape, eye_center, radius, seg_mask)
    
    # è®¡ç®—é”åº¦
    sharpness = calculate_sharpness(img, head_mask)
    
    # å¯è§†åŒ–
    vis_path = visualize_result(img, seg_mask, head_mask, circle_mask, 
                                 eye_center, beak, radius, sharpness, filename, beak_visible)
    
    return {
        'filename': filename,
        'status': 'ok',
        'eye_used': eye_name,
        'radius': radius,
        'sharpness': sharpness,
        'beak_visible': beak_visible,
        'visualization': vis_path
    }


def main():
    print("\n" + "="*60)
    print("ğŸ¦ å¤´éƒ¨åŒºåŸŸé”åº¦æµ‹è¯•")
    print("="*60)
    
    device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
    print(f"è®¾å¤‡: {device}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # åŠ è½½æ¨¡å‹
    print("åŠ è½½å…³é”®ç‚¹æ¨¡å‹...")
    keypoint_model = PartLocalizer()
    checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)
    keypoint_model.load_state_dict(checkpoint['model_state_dict'])
    keypoint_model.to(device).eval()
    
    print("åŠ è½½YOLOæ¨¡å‹...")
    yolo_model = YOLO(YOLO_MODEL_PATH)
    
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # æµ‹è¯•å…¨éƒ¨ç›®å½•
    test_dir = "/Users/jameszhenyu/Desktop/2025-10-18/3æ˜Ÿ_ä¼˜é€‰"
    raw_files = [f for f in os.listdir(test_dir) if f.lower().endswith('.nef') and not os.path.isdir(os.path.join(test_dir, f))]
    
    # æ„å»ºå®Œæ•´è·¯å¾„
    raw_paths = [os.path.join(test_dir, f) for f in raw_files]
    
    print(f"\\næµ‹è¯• {len(raw_paths)} å¼ å›¾ç‰‡...")
    print("-"*60)
    
    results = []
    for i, raw_path in enumerate(raw_paths, 1):
        jpg_path = os.path.splitext(raw_path)[0] + '.jpg'
        
        # è½¬æ¢ RAW åˆ° JPG
        raw_to_jpeg(raw_path)
        
        if not os.path.exists(jpg_path):
            print(f"[{i}] {os.path.basename(raw_path)} - è½¬æ¢å¤±è´¥")
            continue
        
        try:
            result = process_image(jpg_path, yolo_model, keypoint_model, device, transform)
            if result and result['status'] == 'ok':
                beak_status = "âœ“" if result['beak_visible'] else "âœ—æ— å–™"
                print(f"[{i}] {result['filename']}")
                print(f"    çœ¼ç›: {result['eye_used']}, åŠå¾„: {result['radius']:.0f}px, é”åº¦: {result['sharpness']:.0f}, å–™: {beak_status}")
                results.append(result)
            elif result:
                print(f"[{i}] {os.path.basename(raw_path)} - {result['status']}")
        except Exception as e:
            print(f"[{i}] {os.path.basename(raw_path)} - é”™è¯¯: {e}")
        finally:
            if os.path.exists(jpg_path):
                os.remove(jpg_path)
    
    print("\n" + "="*60)
    print(f"âœ… å®Œæˆï¼å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_DIR}")
    print(f"   å…±å¤„ç† {len(results)} å¼ å›¾ç‰‡")
    print("="*60)


if __name__ == "__main__":
    main()
